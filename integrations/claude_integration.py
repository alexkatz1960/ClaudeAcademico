#!/usr/bin/env python3
"""
üß† CLAUDE_INTEGRATION.PY - Integraci√≥n Claude (Anthropic) API
Sistema de Traducci√≥n Acad√©mica v2.2 - APIs Integration Layer
POST-AUDITOR√çA: Versi√≥n mejorada con correcciones cr√≠ticas

Integraci√≥n especializada con Claude API para an√°lisis terminol√≥gico
acad√©mico y refinamiento de traducciones especializadas.

Caracter√≠sticas:
‚úÖ An√°lisis terminol√≥gico especializado por disciplina
‚úÖ Refinamiento de traducciones t√©cnicas y acad√©micas
‚úÖ Generaci√≥n de glosarios biling√ºes estructurados
‚úÖ Prompts optimizados para cada √°rea de conocimiento
‚úÖ Sugerencias contextuales inteligentes
‚úÖ Parsing robusto con m√∫ltiples fallbacks
‚úÖ Validaci√≥n estructural estricta de respuestas JSON
‚úÖ Modelo configurable con fallbacks autom√°ticos

Autor: Sistema ClaudeAcademico v2.2
Fecha: Enero 2025 (Post-Auditor√≠a)
Ubicaci√≥n: integrations/claude_integration.py
"""

import json
import re
from typing import List, Optional, Dict, Any, Union
from dataclasses import asdict

from .base_client import BaseAPIClient, create_rate_limiter
from .models import (
    APIProvider, APIResponse, TerminologySuggestion, AcademicDiscipline,
    SupportedLanguage, Logger, CacheManager, ErrorPolicyManager,
    ACADEMIC_CONTEXTS, get_language_name, create_request_id
)


# ===============================================================================
# CLAUDE (ANTHROPIC) API INTEGRATION (MEJORADA)
# ===============================================================================

class ClaudeAPIIntegration(BaseAPIClient):
    """
    Integraci√≥n con Claude (Anthropic) API para an√°lisis terminol√≥gico acad√©mico.
    
    ‚úÖ POST-AUDITOR√çA: Versi√≥n mejorada con robustez enterprise-grade.
    
    Claude excela en an√°lisis de texto acad√©mico y contextual, siendo ideal para:
    - Identificaci√≥n de terminolog√≠a t√©cnica especializada
    - An√°lisis sem√°ntico profundo de conceptos acad√©micos
    - Generaci√≥n de glosarios biling√ºes contextualizados
    - Refinamiento de traducciones con precisi√≥n disciplinaria
    
    Caracter√≠sticas Enterprise:
    ‚úÖ Prompts especializados por disciplina acad√©mica
    ‚úÖ An√°lisis contextual profundo de terminolog√≠a
    ‚úÖ Generaci√≥n de glosarios estructurados JSON
    ‚úÖ Modelo configurable con fallbacks autom√°ticos
    ‚úÖ Parsing robusto con validaci√≥n estructural
    ‚úÖ Rate limiting autom√°tico (200 req/min)
    ‚úÖ Fallbacks inteligentes y recuperaci√≥n de errores
    ‚úÖ M√©tricas detalladas de uso y performance
    """
    
    def __init__(self,
                 api_key: str,
                 logger: Logger,
                 cache_manager: Optional[CacheManager] = None,
                 error_policy_manager: Optional[ErrorPolicyManager] = None,
                 model: Optional[str] = None,  # ‚úÖ NUEVO: Modelo configurable
                 fallback_model: Optional[str] = None):  # ‚úÖ NUEVO: Modelo de fallback
        
        # ‚úÖ VALIDACI√ìN: API key de Claude
        if not validate_claude_api_key(api_key):
            raise ValueError("API key de Claude inv√°lida (debe empezar con 'sk-ant-')")
        
        # Rate limiter espec√≠fico de Claude: 200 requests/minuto
        rate_limiter = create_rate_limiter(APIProvider.CLAUDE, logger)
        
        super().__init__(
            api_key=api_key,
            base_url="https://api.anthropic.com/v1/",
            provider=APIProvider.CLAUDE,
            logger=logger,
            cache_manager=cache_manager,
            error_policy_manager=error_policy_manager,
            rate_limiter=rate_limiter
        )
        
        # Headers espec√≠ficos de Anthropic
        self.headers.update({
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json"
        })
        
        # ‚úÖ MEJORA CR√çTICA: Modelo configurable con fallbacks
        self.primary_model = model or "claude-3-sonnet-20240229"
        self.fallback_model = fallback_model or "claude-3-haiku-20240307"
        self.current_model = self.primary_model
        
        # Configuraci√≥n para an√°lisis acad√©mico
        self.academic_config = {
            "temperature": 0.3,  # M√°s conservador para terminolog√≠a
            "max_tokens": 3000,
            "top_p": 0.9
        }
        
        # ‚úÖ NUEVO: Configuraciones espec√≠ficas por tarea
        self.task_configs = {
            "terminology": {"temperature": 0.3, "max_tokens": 3000},
            "refinement": {"temperature": 0.2, "max_tokens": 3000},
            "glossary": {"temperature": 0.1, "max_tokens": 4000},
            "quality": {"temperature": 0.2, "max_tokens": 3000}
        }
    
    def _estimate_cost(self, characters: int) -> float:
        """
        Estima costo Claude basado en tokens.
        
        Claude pricing: $3/1M tokens input, $15/1M tokens output
        Estimaci√≥n: 4 chars ‚âà 1 token, promedio input/output 50/50
        """
        estimated_tokens = characters / 4
        input_cost = (estimated_tokens / 1_000_000) * 3.0
        output_cost = (estimated_tokens * 0.5 / 1_000_000) * 15.0  # Output t√≠picamente menor
        return input_cost + output_cost
    
    # ‚úÖ MEJORA CR√çTICA: M√©todo centralizado para llamadas a Claude
    async def _call_claude(self,
                         prompt: str,
                         task_type: str = "general",
                         use_fallback_on_error: bool = True,
                         cache_ttl: int = 3600,
                         use_cache: bool = True) -> APIResponse:
        """
        M√©todo centralizado para todas las llamadas a Claude API.
        
        Args:
            prompt: Prompt a enviar a Claude
            task_type: Tipo de tarea ("terminology", "refinement", "glossary", "quality")
            use_fallback_on_error: Si usar modelo fallback en caso de error
            cache_ttl: TTL para cache
            use_cache: Si usar cache
            
        Returns:
            APIResponse con respuesta de Claude
        """
        # Obtener configuraci√≥n espec√≠fica de la tarea
        config = self.task_configs.get(task_type, self.academic_config)
        
        # Preparar datos para la request
        data = {
            "model": self.current_model,
            "messages": [{"role": "user", "content": prompt}],
            **config
        }
        
        self.logger.debug(f"üß† Claude: Llamada {task_type} con modelo {self.current_model}")
        
        response = await self._make_request(
            "POST",
            "messages",
            data=data,
            cache_ttl=cache_ttl,
            use_cache=use_cache
        )
        
        # ‚úÖ MEJORA: Si falla y tenemos fallback, intentar con modelo alternativo
        if not response.success and use_fallback_on_error and self.current_model != self.fallback_model:
            self.logger.warning(f"‚ö†Ô∏è Claude: Error con {self.current_model}, intentando fallback {self.fallback_model}")
            
            # Temporalmente cambiar a modelo fallback
            original_model = self.current_model
            self.current_model = self.fallback_model
            
            try:
                data["model"] = self.fallback_model
                response = await self._make_request(
                    "POST",
                    "messages",
                    data=data,
                    cache_ttl=cache_ttl,
                    use_cache=False  # No cachear fallbacks
                )
                
                if response.success:
                    self.logger.info(f"‚úÖ Claude: Fallback exitoso con {self.fallback_model}")
                else:
                    self.logger.error(f"‚ùå Claude: Fallback tambi√©n fall√≥ con {self.fallback_model}")
                
            finally:
                # Restaurar modelo original
                self.current_model = original_model
        
        return response
    
    def _extract_claude_content(self, response_data: Dict[str, Any]) -> str:
        """
        ‚úÖ NUEVO: Extrae contenido de respuesta Claude de forma robusta.
        
        Args:
            response_data: Datos de respuesta de Claude API
            
        Returns:
            Contenido de texto extra√≠do
        """
        try:
            # Formato est√°ndar de Claude
            content = response_data.get("content", [])
            if content and isinstance(content, list) and len(content) > 0:
                return content[0].get("text", "")
            
            # Fallback: buscar texto directamente
            if "text" in response_data:
                return response_data["text"]
            
            # √öltimo fallback: convertir a string
            return str(response_data)
            
        except Exception as e:
            self.logger.error(f"‚ùå Claude: Error extrayendo contenido: {e}")
            return ""
    
    async def health_check(self) -> bool:
        """Verifica salud de Claude API con test simple."""
        try:
            test_response = await self.analyze_terminology(
                text_sample="Test health check for academic terminology analysis.",
                discipline=AcademicDiscipline.GENERAL,
                source_lang=SupportedLanguage.ENGLISH,
                max_terms=1
            )
            
            # Considerar exitoso si Claude responde, incluso con errores de parsing
            if test_response.success or "analysis" in str(test_response.data):
                self.logger.info("‚úÖ Claude: Health check exitoso")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"‚ùå Claude health check fall√≥: {e}")
            return False
    
    async def analyze_terminology(self,
                                text_sample: str,
                                discipline: AcademicDiscipline,
                                source_lang: SupportedLanguage,
                                max_terms: int = 15) -> APIResponse:
        """
        Analiza texto acad√©mico para sugerir t√©rminos para glosario.
        
        ‚úÖ POST-AUDITOR√çA: Con validaci√≥n estructural y parsing robusto.
        
        Args:
            text_sample: Muestra de texto para analizar (m√°x 3000 chars)
            discipline: Disciplina acad√©mica para especializaci√≥n
            source_lang: Idioma del texto de origen
            max_terms: M√°ximo n√∫mero de t√©rminos a sugerir
            
        Returns:
            APIResponse con lista de TerminologySuggestion
        """
        # ‚úÖ MEJORA: Validaci√≥n m√°s robusta
        if not text_sample or not text_sample.strip():
            return APIResponse(
                success=False,
                data=None,
                provider=self.provider,
                request_id=create_request_id(self.provider),
                response_time=0.0,
                error_message="text_sample no puede estar vac√≠o"
            )
        
        # Validar max_terms
        if max_terms <= 0 or max_terms > 50:
            max_terms = min(max(max_terms, 1), 50)
            self.logger.warning(f"‚ö†Ô∏è Claude: max_terms ajustado a {max_terms}")
        
        if len(text_sample) > 3000:
            text_sample = text_sample[:3000] + "..."
            self.logger.warning(f"‚ö†Ô∏è Claude: Texto truncado a 3000 caracteres")
        
        context = ACADEMIC_CONTEXTS.get(discipline, ACADEMIC_CONTEXTS[AcademicDiscipline.GENERAL])
        lang_name = get_language_name(source_lang)
        
        prompt = self._create_terminology_prompt(text_sample, context, lang_name, max_terms)
        
        self.logger.info(f"üîç Claude: Analizando terminolog√≠a {discipline.value} ({source_lang.value})")
        
        response = await self._call_claude(
            prompt=prompt,
            task_type="terminology",
            cache_ttl=7200  # Cache por 2 horas
        )
        
        if response.success:
            try:
                # Extraer contenido de la respuesta Claude
                claude_text = self._extract_claude_content(response.data)
                
                if not claude_text:
                    raise ValueError("Respuesta vac√≠a de Claude")
                
                # ‚úÖ MEJORA CR√çTICA: Parsear respuesta con validaci√≥n estructural
                terminology_data = self._parse_terminology_response_robust(claude_text, discipline)
                
                # Crear an√°lisis adicional
                analysis_summary = self._create_analysis_summary(terminology_data)
                
                self.logger.info(f"‚úÖ Claude: {len(terminology_data)} t√©rminos sugeridos para {discipline.value}")
                
                response.data = {
                    "suggestions": [asdict(suggestion) for suggestion in terminology_data],
                    "discipline": discipline.value,
                    "source_language": source_lang.value,
                    "analysis_summary": analysis_summary,
                    "raw_response": claude_text,
                    "model_used": self.current_model,
                    "validation_passed": True
                }
                
            except Exception as e:
                self.logger.error(f"‚ùå Claude: Error parseando respuesta terminol√≥gica: {e}")
                
                # ‚úÖ MEJORA: Fallback mejorado
                claude_text = self._extract_claude_content(response.data)
                fallback_terms = self._manual_parse_terminology_enhanced(claude_text, discipline)
                
                response.data = {
                    "suggestions": [asdict(term) for term in fallback_terms],
                    "discipline": discipline.value,
                    "source_language": source_lang.value,
                    "analysis_summary": {
                        "parsing_method": "enhanced_fallback", 
                        "total_terms": len(fallback_terms),
                        "confidence_average": sum(t.confidence for t in fallback_terms) / len(fallback_terms) if fallback_terms else 0.0
                    },
                    "raw_response": claude_text,
                    "parsing_error": str(e),
                    "validation_passed": False
                }
                
                if not fallback_terms:
                    response.success = False
                    response.error_message = f"Error parseando terminolog√≠a: {e}"
        
        return response
    
    async def refine_translation(self,
                               original_text: str,
                               translated_text: str,
                               discipline: AcademicDiscipline,
                               source_lang: SupportedLanguage) -> APIResponse:
        """
        Refina traducci√≥n para mejorar precisi√≥n acad√©mica.
        
        ‚úÖ POST-AUDITOR√çA: Con m√©todo centralizado y validaci√≥n robusta.
        """
        # Validar inputs
        if not original_text or not translated_text:
            return APIResponse(
                success=False,
                data=None,
                provider=self.provider,
                request_id=create_request_id(self.provider),
                response_time=0.0,
                error_message="original_text y translated_text son requeridos"
            )
        
        # Truncar textos si son muy largos
        if len(original_text) > 1500:
            original_text = original_text[:1500] + "..."
            self.logger.warning("‚ö†Ô∏è Claude: original_text truncado a 1500 caracteres")
        if len(translated_text) > 1500:
            translated_text = translated_text[:1500] + "..."
            self.logger.warning("‚ö†Ô∏è Claude: translated_text truncado a 1500 caracteres")
        
        context = ACADEMIC_CONTEXTS.get(discipline, ACADEMIC_CONTEXTS[AcademicDiscipline.GENERAL])
        lang_name = get_language_name(source_lang)
        
        prompt = self._create_refinement_prompt(original_text, translated_text, context, lang_name)
        
        self.logger.info(f"üîß Claude: Refinando traducci√≥n {discipline.value}")
        
        response = await self._call_claude(
            prompt=prompt,
            task_type="refinement",
            use_cache=False  # No cachear refinamientos espec√≠ficos
        )
        
        if response.success:
            try:
                claude_text = self._extract_claude_content(response.data)
                refinement_data = self._parse_refinement_response_robust(claude_text)
                
                improvements_count = len(refinement_data.get("mejoras_aplicadas", []))
                self.logger.info(f"‚úÖ Claude: Traducci√≥n refinada con {improvements_count} mejoras")
                
                response.data = {
                    **refinement_data,
                    "original_length": len(original_text),
                    "translation_length": len(translated_text),
                    "discipline": discipline.value,
                    "model_used": self.current_model,
                    "raw_response": claude_text
                }
                
            except Exception as e:
                self.logger.error(f"‚ùå Claude: Error parseando refinamiento: {e}")
                response.success = False
                response.error_message = f"Error parseando refinamiento: {e}"
        
        return response
    
    async def generate_glossary_entries(self,
                                      terms_list: List[str],
                                      discipline: AcademicDiscipline,
                                      source_lang: SupportedLanguage) -> APIResponse:
        """
        Genera entradas de glosario para lista de t√©rminos.
        
        ‚úÖ POST-AUDITOR√çA: Con validaci√≥n de entrada mejorada.
        """
        if not terms_list or len(terms_list) == 0:
            return APIResponse(
                success=False,
                data=None,
                provider=self.provider,
                request_id=create_request_id(self.provider),
                response_time=0.0,
                error_message="Lista de t√©rminos vac√≠a"
            )
        
        # ‚úÖ MEJORA: Filtrar t√©rminos vac√≠os y duplicados
        clean_terms = list(set([term.strip() for term in terms_list if term and term.strip()]))
        
        if not clean_terms:
            return APIResponse(
                success=False,
                data=None,
                provider=self.provider,
                request_id=create_request_id(self.provider),
                response_time=0.0,
                error_message="Todos los t√©rminos est√°n vac√≠os despu√©s de limpieza"
            )
        
        # Limitar a 20 t√©rminos para evitar respuestas muy largas
        if len(clean_terms) > 20:
            clean_terms = clean_terms[:20]
            self.logger.warning(f"‚ö†Ô∏è Claude: Lista de t√©rminos truncada a 20 elementos")
        
        context = ACADEMIC_CONTEXTS.get(discipline, ACADEMIC_CONTEXTS[AcademicDiscipline.GENERAL])
        lang_name = get_language_name(source_lang)
        terms_str = "\n".join([f"- {term}" for term in clean_terms])
        
        prompt = self._create_glossary_prompt(terms_str, context, lang_name)
        
        self.logger.info(f"üìñ Claude: Generando glosario {discipline.value} ({len(clean_terms)} t√©rminos)")
        
        response = await self._call_claude(
            prompt=prompt,
            task_type="glossary",
            cache_ttl=86400  # Cache glosarios por 24 horas
        )
        
        if response.success:
            try:
                claude_text = self._extract_claude_content(response.data)
                glossary_data = self._parse_glossary_response_robust(claude_text, discipline)
                
                entries_count = len(glossary_data.get("glosario", []))
                self.logger.info(f"‚úÖ Claude: Glosario generado con {entries_count} entradas")
                
                response.data = {
                    **glossary_data,
                    "source_terms_count": len(clean_terms),
                    "source_terms_original": len(terms_list),
                    "discipline": discipline.value,
                    "source_language": source_lang.value,
                    "model_used": self.current_model,
                    "raw_response": claude_text
                }
                
            except Exception as e:
                self.logger.error(f"‚ùå Claude: Error parseando glosario: {e}")
                response.success = False
                response.error_message = f"Error parseando glosario: {e}"
        
        return response
    
    async def validate_translation_quality(self,
                                         original_text: str,
                                         translated_text: str,
                                         discipline: AcademicDiscipline) -> APIResponse:
        """
        Valida calidad de traducci√≥n acad√©mica y sugiere mejoras.
        
        ‚úÖ POST-AUDITOR√çA: Con m√©todo centralizado.
        """
        if not original_text or not translated_text:
            return APIResponse(
                success=False,
                data=None,
                provider=self.provider,
                request_id=create_request_id(self.provider),
                response_time=0.0,
                error_message="original_text y translated_text son requeridos"
            )
        
        context = ACADEMIC_CONTEXTS.get(discipline, ACADEMIC_CONTEXTS[AcademicDiscipline.GENERAL])
        
        prompt = self._create_quality_validation_prompt(original_text, translated_text, context, discipline)
        
        self.logger.info(f"üìä Claude: Validando calidad de traducci√≥n {discipline.value}")
        
        response = await self._call_claude(
            prompt=prompt,
            task_type="quality",
            use_cache=False
        )
        
        if response.success:
            try:
                claude_text = self._extract_claude_content(response.data)
                quality_data = self._parse_quality_response_robust(claude_text)
                
                quality_score = quality_data.get("calidad_general", 0.0)
                self.logger.info(f"‚úÖ Claude: An√°lisis de calidad completado (score: {quality_score:.2f})")
                
                response.data = {
                    **quality_data,
                    "discipline": discipline.value,
                    "text_lengths": {
                        "original": len(original_text),
                        "translated": len(translated_text)
                    },
                    "model_used": self.current_model,
                    "raw_response": claude_text
                }
                
            except Exception as e:
                self.logger.error(f"‚ùå Claude: Error parseando an√°lisis de calidad: {e}")
                response.success = False
                response.error_message = f"Error parseando an√°lisis de calidad: {e}"
        
        return response
    
    # ===============================================================================
    # M√âTODOS DE CREACI√ìN DE PROMPTS (SIN CAMBIOS SIGNIFICATIVOS)
    # ===============================================================================
    
    def _create_terminology_prompt(self, text: str, context: str, lang_name: str, max_terms: int) -> str:
        """Crea prompt especializado para an√°lisis terminol√≥gico."""
        return f"""
Eres un experto termin√≥logo acad√©mico especializado en an√°lisis de textos especializados.

TAREA: Analizar el siguiente texto en {lang_name} e identificar t√©rminos t√©cnicos clave para crear un glosario biling√ºe {lang_name}-espa√±ol.

CONTEXTO DISCIPLINARIO: {context}

TEXTO A ANALIZAR:
{text}

CRITERIOS DE SELECCI√ìN DE T√âRMINOS:
1. T√©rminos t√©cnicos espec√≠ficos de la disciplina
2. Conceptos que requieren consistencia terminol√≥gica
3. Palabras que pueden tener m√∫ltiples traducciones seg√∫n contexto
4. T√©rminos frecuentes en textos acad√©micos de este campo
5. Conceptos que pueden ser malinterpretados si se traducen incorrectamente

FORMATO DE RESPUESTA (JSON v√°lido):
{{
    "terminos_sugeridos": [
        {{
            "termino_original": "Dasein",
            "traduccion_sugerida": "ser-ah√≠",
            "contexto": "filosof√≠a heideggeriana, an√°lisis existencial",
            "justificacion": "T√©rmino t√©cnico fundamental que requiere consistencia",
            "confianza": 0.95,
            "prioridad": "alta",
            "frecuencia_estimada": "media",
            "alternativas": ["existencia", "ser-en-el-mundo"]
        }}
    ],
    "resumen_analisis": {{
        "total_terminos_identificados": {max_terms},
        "disciplinas_detectadas": ["filosof√≠a", "ontolog√≠a"],
        "nivel_especializacion": "alto",
        "recomendaciones": "Priorizar t√©rminos fenomenol√≥gicos y ontol√≥gicos"
    }}
}}

IMPORTANTE: 
- M√°ximo {max_terms} t√©rminos m√°s relevantes
- Responder SOLO con JSON v√°lido, sin texto adicional
- Incluir justificaci√≥n acad√©mica para cada t√©rmino
"""
    
    def _create_refinement_prompt(self, original: str, translation: str, context: str, lang_name: str) -> str:
        """Crea prompt para refinamiento de traducci√≥n."""
        return f"""
Eres un experto traductor acad√©mico especializado en {context}.

TAREA: Refinar la siguiente traducci√≥n acad√©mica de {lang_name} al espa√±ol, mejorando la precisi√≥n terminol√≥gica y el estilo acad√©mico.

CONTEXTO DISCIPLINARIO: {context}

TEXTO ORIGINAL ({lang_name}):
{original}

TRADUCCI√ìN INICIAL (Espa√±ol):
{translation}

INSTRUCCIONES DE REFINAMIENTO:
1. Identificar t√©rminos t√©cnicos que pueden mejorarse
2. Proponer alternativas m√°s precisas para t√©rminos especializados
3. Mantener el estilo acad√©mico formal apropiado
4. Preservar el significado y estructura originales
5. Asegurar consistencia terminol√≥gica

FORMATO DE RESPUESTA (JSON v√°lido):
{{
    "traduccion_refinada": "versi√≥n mejorada de la traducci√≥n completa",
    "mejoras_aplicadas": [
        {{
            "posicion": "p√°rrafo 1",
            "original": "t√©rmino original",
            "inicial": "traducci√≥n inicial",
            "refinada": "traducci√≥n mejorada", 
            "justificacion": "raz√≥n acad√©mica espec√≠fica de la mejora",
            "tipo_mejora": "terminolog√≠a|estilo|precisi√≥n|fluidez"
        }}
    ],
    "calidad_mejora": {{
        "confianza_general": 0.95,
        "areas_mejoradas": ["terminolog√≠a especializada", "fluidez acad√©mica"],
        "riesgo_cambios": "bajo"
    }},
    "observaciones": "comentarios adicionales sobre la traducci√≥n y el proceso de refinamiento"
}}

IMPORTANTE: Responder SOLO con JSON v√°lido, sin texto adicional.
"""
    
    def _create_glossary_prompt(self, terms_str: str, context: str, lang_name: str) -> str:
        """Crea prompt para generaci√≥n de glosario."""
        return f"""
Eres un termin√≥logo experto en {context} especializado en glosarios acad√©micos biling√ºes.

TAREA: Crear entradas de glosario completas para los siguientes t√©rminos de {lang_name} al espa√±ol.

CONTEXTO DISCIPLINARIO: {context}

T√âRMINOS A PROCESAR:
{terms_str}

INSTRUCCIONES:
1. Para cada t√©rmino, proporcionar la mejor traducci√≥n al espa√±ol acad√©mico
2. Incluir contexto disciplinario espec√≠fico y definici√≥n breve
3. Indicar nivel de confianza en la traducci√≥n
4. Sugerir t√©rminos relacionados cuando sea relevante
5. Identificar casos donde se requiere nota explicativa

FORMATO DE RESPUESTA (JSON v√°lido):
{{
    "glosario": [
        {{
            "termino_original": "Begriff",
            "traduccion_principal": "concepto",
            "traducciones_alternativas": ["noci√≥n", "idea"],
            "contexto_disciplinario": "filosof√≠a alemana, especialmente en Hegel y Kant",
            "definicion_breve": "unidad de pensamiento que representa algo universal",
            "nota_explicativa": "En Hegel, se refiere espec√≠ficamente al concepto que se desarrolla dial√©cticamente",
            "confianza": 0.95,
            "frecuencia_estimada": "alta",
            "terminos_relacionados": ["Vorstellung", "Gedanke", "Idee"],
            "requiere_contexto": true
        }}
    ],
    "estadisticas": {{
        "total_terminos": 5,
        "confianza_promedio": 0.92,
        "terminos_alta_confianza": 4,
        "terminos_revision_necesaria": 1,
        "areas_tematicas": ["ontolog√≠a", "epistemolog√≠a"]
    }},
    "recomendaciones_uso": [
        "Mantener consistencia en traducci√≥n de t√©rminos t√©cnicos",
        "Incluir notas explicativas para t√©rminos con m√∫ltiples acepciones"
    ]
}}

IMPORTANTE: Responder SOLO con JSON v√°lido, sin texto adicional.
"""
    
    def _create_quality_validation_prompt(self, original: str, translated: str, context: str, discipline: AcademicDiscipline) -> str:
        """‚úÖ NUEVO: Crea prompt optimizado para validaci√≥n de calidad."""
        return f"""
Eres un experto en traducci√≥n acad√©mica especializado en {discipline.value}.

TAREA: Evaluar la calidad de la siguiente traducci√≥n acad√©mica y proporcionar an√°lisis detallado.

CONTEXTO DISCIPLINARIO: {context}

TEXTO ORIGINAL:
{original[:1000]}

TRADUCCI√ìN A EVALUAR:
{translated[:1000]}

CRITERIOS DE EVALUACI√ìN:
1. Precisi√≥n terminol√≥gica especializada
2. Preservaci√≥n del significado acad√©mico
3. Fluidez y naturalidad en espa√±ol acad√©mico
4. Consistencia terminol√≥gica
5. Adecuaci√≥n al registro acad√©mico

FORMATO DE RESPUESTA (JSON v√°lido):
{{
    "calidad_general": 0.85,
    "criterios_evaluacion": {{
        "precision_terminologica": 0.90,
        "preservacion_significado": 0.85,
        "fluidez_academica": 0.80,
        "consistencia_terminologica": 0.85,
        "registro_academico": 0.90
    }},
    "fortalezas": [
        "Excelente manejo de terminolog√≠a filos√≥fica",
        "Preservaci√≥n del registro acad√©mico formal"
    ],
    "areas_mejora": [
        "Inconsistencia en traducci√≥n de 'Begriff'",
        "Algunas construcciones poco naturales"
    ],
    "sugerencias_especificas": [
        {{
            "fragmento_original": "texto problem√°tico",
            "traduccion_actual": "traducci√≥n actual", 
            "mejora_sugerida": "mejora propuesta",
            "justificacion": "raz√≥n de la mejora"
        }}
    ],
    "recomendacion_general": "Traducci√≥n de buena calidad que requiere ajustes menores en terminolog√≠a espec√≠fica"
}}

IMPORTANTE: Responder SOLO con JSON v√°lido, sin texto adicional.
"""
    
    # ===============================================================================
    # M√âTODOS DE PARSING ROBUSTOS (MEJORADOS)
    # ===============================================================================
    
    def _parse_terminology_response_robust(self, claude_text: str, discipline: AcademicDiscipline) -> List[TerminologySuggestion]:
        """
        ‚úÖ MEJORA CR√çTICA: Parsea respuesta con validaci√≥n estructural estricta.
        """
        try:
            # Intentar extraer JSON de la respuesta
            json_text = self._extract_json_from_text_robust(claude_text)
            
            if json_text:
                data = json.loads(json_text)
                
                # ‚úÖ VALIDACI√ìN ESTRUCTURAL: Verificar claves requeridas
                if not self._validate_terminology_structure(data):
                    raise ValueError("Estructura JSON de terminolog√≠a inv√°lida")
                
                suggestions = []
                for term_data in data.get("terminos_sugeridos", []):
                    # ‚úÖ VALIDACI√ìN: Campos m√≠nimos requeridos
                    if not all(key in term_data for key in ["termino_original", "traduccion_sugerida"]):
                        self.logger.warning(f"‚ö†Ô∏è Claude: T√©rmino incompleto ignorado: {term_data}")
                        continue
                    
                    suggestion = TerminologySuggestion(
                        source_term=term_data.get("termino_original", ""),
                        target_term=term_data.get("traduccion_sugerida", ""),
                        context=term_data.get("contexto", ""),
                        discipline=discipline,
                        confidence=float(term_data.get("confianza", 0.5)),
                        justification=term_data.get("justificacion", ""),
                        priority=term_data.get("prioridad", "medium"),
                        frequency_estimate=term_data.get("frecuencia_estimada", "unknown")
                    )
                    suggestions.append(suggestion)
                
                return suggestions
            
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            self.logger.warning(f"‚ö†Ô∏è Claude: Error parseando JSON terminol√≥gico, usando fallback: {e}")
        
        # Fallback: parsing manual mejorado
        return self._manual_parse_terminology_enhanced(claude_text, discipline)
    
    def _parse_refinement_response_robust(self, claude_text: str) -> dict:
        """‚úÖ MEJORA CR√çTICA: Parsea refinamiento con validaci√≥n."""
        try:
            json_text = self._extract_json_from_text_robust(claude_text)
            if json_text:
                data = json.loads(json_text)
                
                # ‚úÖ VALIDACI√ìN ESTRUCTURAL
                if not self._validate_refinement_structure(data):
                    raise ValueError("Estructura JSON de refinamiento inv√°lida")
                
                return data
                
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            self.logger.warning(f"‚ö†Ô∏è Claude: Error parseando refinamiento: {e}")
        
        # Fallback b√°sico mejorado
        return {
            "traduccion_refinada": "Error parseando refinamiento - revisar respuesta manual",
            "mejoras_aplicadas": [],
            "calidad_mejora": {"confianza_general": 0.0, "areas_mejoradas": [], "riesgo_cambios": "alto"},
            "observaciones": f"Error en parsing autom√°tico: {claude_text[:200]}..."
        }
    
    def _parse_glossary_response_robust(self, claude_text: str, discipline: AcademicDiscipline) -> dict:
        """‚úÖ MEJORA CR√çTICA: Parsea glosario con validaci√≥n."""
        try:
            json_text = self._extract_json_from_text_robust(claude_text)
            if json_text:
                data = json.loads(json_text)
                
                # ‚úÖ VALIDACI√ìN ESTRUCTURAL
                if not self._validate_glossary_structure(data):
                    raise ValueError("Estructura JSON de glosario inv√°lida")
                
                return data
                
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            self.logger.warning(f"‚ö†Ô∏è Claude: Error parseando glosario: {e}")
        
        # Fallback b√°sico mejorado
        return {
            "glosario": [],
            "estadisticas": {
                "total_terminos": 0,
                "confianza_promedio": 0.0,
                "terminos_alta_confianza": 0,
                "terminos_revision_necesaria": 0,
                "areas_tematicas": [discipline.value]
            },
            "recomendaciones_uso": ["Revisi√≥n manual necesaria debido a error de parsing"]
        }
    
    def _parse_quality_response_robust(self, claude_text: str) -> dict:
        """‚úÖ MEJORA CR√çTICA: Parsea an√°lisis de calidad con validaci√≥n."""
        try:
            json_text = self._extract_json_from_text_robust(claude_text)
            if json_text:
                data = json.loads(json_text)
                
                # ‚úÖ VALIDACI√ìN ESTRUCTURAL
                if not self._validate_quality_structure(data):
                    raise ValueError("Estructura JSON de calidad inv√°lida")
                
                return data
                
        except (json.JSONDecodeError, ValueError, TypeError) as e:
            self.logger.warning(f"‚ö†Ô∏è Claude: Error parseando calidad: {e}")
        
        # Fallback b√°sico
        return {
            "calidad_general": 0.0,
            "criterios_evaluacion": {
                "precision_terminologica": 0.0,
                "preservacion_significado": 0.0,
                "fluidez_academica": 0.0,
                "consistencia_terminologica": 0.0,
                "registro_academico": 0.0
            },
            "fortalezas": [],
            "areas_mejora": ["Error en an√°lisis autom√°tico"],
            "sugerencias_especificas": [],
            "recomendacion_general": "Revisi√≥n manual necesaria debido a error de parsing"
        }
    
    # ===============================================================================
    # M√âTODOS DE VALIDACI√ìN ESTRUCTURAL (NUEVOS)
    # ===============================================================================
    
    def _validate_terminology_structure(self, data: dict) -> bool:
        """‚úÖ NUEVO: Valida estructura de respuesta terminol√≥gica."""
        required_keys = ["terminos_sugeridos"]
        
        if not all(key in data for key in required_keys):
            return False
        
        # Validar que terminos_sugeridos sea una lista
        if not isinstance(data["terminos_sugeridos"], list):
            return False
        
        # Validar estructura de cada t√©rmino
        for term in data["terminos_sugeridos"]:
            if not isinstance(term, dict):
                return False
            if not all(key in term for key in ["termino_original", "traduccion_sugerida"]):
                return False
        
        return True
    
    def _validate_refinement_structure(self, data: dict) -> bool:
        """‚úÖ NUEVO: Valida estructura de respuesta de refinamiento."""
        required_keys = ["traduccion_refinada", "mejoras_aplicadas", "calidad_mejora"]
        
        if not all(key in data for key in required_keys):
            return False
        
        # Validar tipos
        if not isinstance(data["mejoras_aplicadas"], list):
            return False
        if not isinstance(data["calidad_mejora"], dict):
            return False
        
        return True
    
    def _validate_glossary_structure(self, data: dict) -> bool:
        """‚úÖ NUEVO: Valida estructura de respuesta de glosario."""
        required_keys = ["glosario", "estadisticas"]
        
        if not all(key in data for key in required_keys):
            return False
        
        # Validar tipos
        if not isinstance(data["glosario"], list):
            return False
        if not isinstance(data["estadisticas"], dict):
            return False
        
        return True
    
    def _validate_quality_structure(self, data: dict) -> bool:
        """‚úÖ NUEVO: Valida estructura de respuesta de calidad."""
        required_keys = ["calidad_general", "criterios_evaluacion", "fortalezas", "areas_mejora"]
        
        if not all(key in data for key in required_keys):
            return False
        
        # Validar tipos y rangos
        if not isinstance(data["calidad_general"], (int, float)) or not (0 <= data["calidad_general"] <= 1):
            return False
        
        if not isinstance(data["criterios_evaluacion"], dict):
            return False
        
        if not isinstance(data["fortalezas"], list) or not isinstance(data["areas_mejora"], list):
            return False
        
        return True
    
    def _extract_json_from_text_robust(self, text: str) -> Optional[str]:
        """
        ‚úÖ MEJORA CR√çTICA: Extrae JSON con mejor tolerancia a formatos.
        """
        if not text or not text.strip():
            return None
        
        # Limpiar texto
        text = text.strip()
        
        # M√©todo 1: Buscar JSON entre llaves (m√°s estricto)
        json_match = re.search(r'\{(?:[^{}]|{[^{}]*})*\}', text, re.DOTALL)
        if json_match:
            candidate = json_match.group(0)
            if self._is_valid_json(candidate):
                return candidate
        
        # M√©todo 2: Buscar JSON entre marcadores de c√≥digo
        code_patterns = [
            r'```(?:json)?\s*(\{.*?\})\s*```',
            r'```(\{.*?\})```',
            r'`(\{.*?\})`'
        ]
        
        for pattern in code_patterns:
            code_match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            if code_match:
                candidate = code_match.group(1)
                if self._is_valid_json(candidate):
                    return candidate
        
        # M√©todo 3: Intentar limpiar JSON com√∫n con errores
        cleaned = self._clean_malformed_json(text)
        if cleaned and self._is_valid_json(cleaned):
            return cleaned
        
        return None
    
    def _is_valid_json(self, text: str) -> bool:
        """‚úÖ NUEVO: Verifica si un texto es JSON v√°lido."""
        try:
            json.loads(text)
            return True
        except (json.JSONDecodeError, ValueError):
            return False
    
    def _clean_malformed_json(self, text: str) -> Optional[str]:
        """
        ‚úÖ NUEVO: Intenta limpiar JSON malformado com√∫n.
        """
        # Buscar entre primera { y √∫ltima }
        start = text.find('{')
        end = text.rfind('}')
        
        if start == -1 or end == -1 or start >= end:
            return None
        
        candidate = text[start:end+1]
        
        # Limpiezas comunes
        # Comillas simples a dobles
        candidate = re.sub(r"'([^']*)':", r'"\1":', candidate)
        
        # Claves sin comillas
        candidate = re.sub(r'([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', candidate)
        
        # Comas finales
        candidate = re.sub(r',(\s*[}\]])', r'\1', candidate)
        
        return candidate
    
    def _manual_parse_terminology_enhanced(self, text: str, discipline: AcademicDiscipline) -> List[TerminologySuggestion]:
        """
        ‚úÖ MEJORA CR√çTICA: Parsing manual mejorado con heur√≠sticas.
        """
        suggestions = []
        lines = text.split('\n')
        
        # Patrones mejorados para detectar t√©rminos
        patterns = [
            r'([^‚Üí:]+)[\s]*‚Üí[\s]*([^‚Üí:]+)',  # t√©rmino ‚Üí traducci√≥n
            r'([^:]+)[\s]*:[\s]*([^:]+)',   # t√©rmino: traducci√≥n
            r'"([^"]+)"[\s]*‚Üí[\s]*"([^"]+)"',  # "t√©rmino" ‚Üí "traducci√≥n"
            r'- ([^:]+):[\s]*([^:\n]+)'     # - t√©rmino: traducci√≥n
        ]
        
        for line in lines:
            line = line.strip()
            if len(line) < 3:  # Ignorar l√≠neas muy cortas
                continue
            
            for pattern in patterns:
                matches = re.findall(pattern, line, re.IGNORECASE)
                for match in matches:
                    if len(match) >= 2:
                        source_term = match[0].strip().strip('"\'').strip('- ')
                        target_term = match[1].strip().strip('"\'').strip('- ')
                        
                        if (source_term and target_term and 
                            len(source_term) > 1 and len(target_term) > 1 and
                            len(source_term) < 100 and len(target_term) < 100):
                            
                            # ‚úÖ MEJORA: Heur√≠sticas para confidence y priority
                            confidence = self._estimate_term_confidence(source_term, target_term, line)
                            priority = self._estimate_term_priority(source_term, discipline)
                            
                            suggestion = TerminologySuggestion(
                                source_term=source_term,
                                target_term=target_term,
                                context="extra√≠do autom√°ticamente con heur√≠sticas",
                                discipline=discipline,
                                confidence=confidence,
                                justification="parsing autom√°tico mejorado de respuesta Claude",
                                priority=priority,
                                frequency_estimate="unknown"
                            )
                            suggestions.append(suggestion)
        
        # Eliminar duplicados por source_term
        seen_terms = set()
        unique_suggestions = []
        for suggestion in suggestions:
            if suggestion.source_term not in seen_terms:
                seen_terms.add(suggestion.source_term)
                unique_suggestions.append(suggestion)
        
        return unique_suggestions[:15]  # M√°ximo 15 t√©rminos en fallback
    
    def _estimate_term_confidence(self, source_term: str, target_term: str, context_line: str) -> float:
        """‚úÖ NUEVO: Estima confidence basado en heur√≠sticas."""
        confidence = 0.5  # Base
        
        # Factores que aumentan confidence
        if len(source_term) > 3:  # T√©rminos m√°s largos tienden a ser m√°s t√©cnicos
            confidence += 0.1
        
        if any(word in context_line.lower() for word in ['concepto', 't√©rmino', 'technical', 'specialized']):
            confidence += 0.2
        
        if '"' in context_line:  # T√©rminos en comillas tienden a ser m√°s precisos
            confidence += 0.1
        
        # Factores que disminuyen confidence
        if len(source_term) < 3 or len(target_term) < 3:
            confidence -= 0.2
        
        if any(word in source_term.lower() for word in ['the', 'and', 'or', 'el', 'la', 'y', 'o']):
            confidence -= 0.1
        
        return max(0.1, min(0.9, confidence))
    
    def _estimate_term_priority(self, source_term: str, discipline: AcademicDiscipline) -> str:
        """‚úÖ NUEVO: Estima priority basado en disciplina y t√©rmino."""
        # T√©rminos t√©cnicos largos tienden a ser m√°s importantes
        if len(source_term) > 8:
            return "alta"
        elif len(source_term) > 4:
            return "media"
        else:
            return "baja"
    
    def _create_analysis_summary(self, suggestions: List[TerminologySuggestion]) -> dict:
        """Crea resumen de an√°lisis terminol√≥gico (sin cambios significativos)."""
        if not suggestions:
            return {
                "total_sugerencias": 0,
                "confianza_promedio": 0.0,
                "prioridades": {"alta": 0, "media": 0, "baja": 0}
            }
        
        total = len(suggestions)
        confianza_promedio = sum(s.confidence for s in suggestions) / total
        
        prioridades = {"alta": 0, "media": 0, "baja": 0}
        for suggestion in suggestions:
            priority_key = suggestion.priority if suggestion.priority in prioridades else "media"
            prioridades[priority_key] += 1
        
        return {
            "total_sugerencias": total,
            "confianza_promedio": confianza_promedio,
            "prioridades": prioridades,
            "terminos_alta_confianza": sum(1 for s in suggestions if s.confidence > 0.8),
            "disciplina": suggestions[0].discipline.value if suggestions else "unknown",
            "terminos_prioritarios": [
                s.source_term for s in suggestions 
                if s.priority == "alta" or s.confidence > 0.9
            ][:5]
        }


# ===============================================================================
# UTILIDADES ESPEC√çFICAS DE CLAUDE (MEJORADAS)
# ===============================================================================

def validate_claude_api_key(api_key: str) -> bool:
    """
    ‚úÖ MEJORADO: Valida formato de API key de Claude/Anthropic con verificaciones adicionales.
    """
    if not api_key or not isinstance(api_key, str):
        return False
    
    # Verificar longitud m√≠nima
    if len(api_key) < 30:
        return False
    
    # Claude API keys empiezan con "sk-ant-"
    if not api_key.startswith("sk-ant-"):
        return False
    
    # ‚úÖ MEJORA: Verificar que tenga formato b√°sico despu√©s del prefijo
    key_part = api_key[7:]  # Remover "sk-ant-"
    
    # Debe tener al menos caracteres alfanum√©ricos y guiones
    if not re.match(r'^[0-9a-zA-Z\-_]+$', key_part):
        return False
    
    # Verificar longitud del key_part
    if len(key_part) < 20:
        return False
    
    return True


def get_supported_models() -> dict:
    """
    ‚úÖ MEJORADO: Retorna modelos Claude soportados con m√°s informaci√≥n.
    """
    return {
        "recommended": {
            "terminology": "claude-3-sonnet-20240229",
            "refinement": "claude-3-sonnet-20240229", 
            "glossary": "claude-3-sonnet-20240229",
            "quality": "claude-3-sonnet-20240229"
        },
        "alternatives": {
            "high_performance": "claude-3-opus-20240229",
            "cost_effective": "claude-3-haiku-20240307"
        },
        "characteristics": {
            "sonnet": "Balance √≥ptimo calidad/velocidad para an√°lisis acad√©mico",
            "opus": "M√°xima calidad para an√°lisis complejos",
            "haiku": "R√°pido y econ√≥mico para tareas simples"
        },
        "pricing": {
            "sonnet": {"input": 3.0, "output": 15.0, "unit": "per_million_tokens"},
            "opus": {"input": 15.0, "output": 75.0, "unit": "per_million_tokens"},
            "haiku": {"input": 0.25, "output": 1.25, "unit": "per_million_tokens"}
        },
        "context_windows": {
            "sonnet": 200000,
            "opus": 200000,
            "haiku": 200000
        }
    }


def estimate_claude_processing_time(text_length: int, complexity: str = "medium", task_type: str = "terminology") -> dict:
    """
    ‚úÖ MEJORADO: Estima tiempo con factores m√°s precisos y espec√≠ficos por tarea.
    """
    # ‚úÖ MEJORA: Factores espec√≠ficos por tipo de tarea
    task_factors = {
        "terminology": 1.0,   # An√°lisis est√°ndar
        "refinement": 1.5,    # Requiere m√°s an√°lisis
        "glossary": 2.0,      # Procesamiento m√°s complejo
        "quality": 1.3        # Evaluaci√≥n detallada
    }
    
    # Factores de complejidad
    complexity_factors = {
        "low": 0.7,     # An√°lisis simple
        "medium": 1.0,  # An√°lisis terminol√≥gico est√°ndar
        "high": 1.8     # An√°lisis profundo + refinamiento
    }
    
    task_factor = task_factors.get(task_type, 1.0)
    complexity_factor = complexity_factors.get(complexity, 1.0)
    
    # ‚úÖ MEJORA: Estimaci√≥n base m√°s precisa: ~3 segundos por 1000 caracteres
    base_time = (text_length / 1000) * 3 * complexity_factor * task_factor
    
    # Tiempo m√≠nimo y m√°ximo
    min_time = max(2, base_time * 0.6)
    max_time = min(120, base_time * 2.0)  # M√°ximo 2 minutos
    
    # ‚úÖ NUEVO: Categor√≠as de tiempo
    if base_time <= 10:
        time_category = "fast"
    elif base_time <= 30:
        time_category = "medium"
    else:
        time_category = "slow"
    
    return {
        "estimated_seconds": int(base_time),
        "min_seconds": int(min_time),
        "max_seconds": int(max_time),
        "complexity_factor": complexity_factor,
        "task_factor": task_factor,
        "time_category": time_category,
        "recommended_model": "claude-3-sonnet-20240229",
        "user_message": _generate_claude_time_message(int(base_time), task_type, time_category)
    }


def _generate_claude_time_message(seconds: int, task_type: str, category: str) -> str:
    """‚úÖ NUEVO: Genera mensaje amigable espec√≠fico para Claude."""
    task_names = {
        "terminology": "an√°lisis terminol√≥gico",
        "refinement": "refinamiento de traducci√≥n",
        "glossary": "generaci√≥n de glosario",
        "quality": "evaluaci√≥n de calidad"
    }
    
    task_name = task_names.get(task_type, "procesamiento")
    
    if category == "fast":
        return f"{task_name.title()} r√°pido (~{seconds}s)"
    elif category == "medium":
        return f"{task_name.title()}: {seconds // 60}m {seconds % 60}s estimado"
    else:
        return f"{task_name.title()} complejo: {seconds // 60}m {seconds % 60}s estimado"


def get_academic_discipline_contexts() -> dict:
    """‚úÖ NUEVO: Contextos acad√©micos disponibles para validaci√≥n."""
    return {
        discipline.value: context 
        for discipline, context in ACADEMIC_CONTEXTS.items()
    }


# ===============================================================================
# TESTS UNITARIOS EMBEBIDOS (MEJORADOS)
# ===============================================================================

async def test_claude_terminology_analysis():
    """‚úÖ MEJORADO: Test b√°sico de an√°lisis terminol√≥gico."""
    import os
    api_key = os.getenv("CLAUDE_API_KEY")
    
    if not api_key or api_key.startswith("your_"):
        print("‚ö†Ô∏è Test Claude omitido: API key no configurada")
        return
    
    import logging
    logger = logging.getLogger("test")
    claude = ClaudeAPIIntegration(api_key, logger)
    
    # Test health check
    is_healthy = await claude.health_check()
    assert is_healthy, "Claude API debe estar disponible"
    
    # Test an√°lisis terminol√≥gico
    sample_text = "The concept of Being in Heidegger's philosophy represents a fundamental way of understanding human existence."
    
    response = await claude.analyze_terminology(
        text_sample=sample_text,
        discipline=AcademicDiscipline.PHILOSOPHY,
        source_lang=SupportedLanguage.ENGLISH,
        max_terms=3
    )
    
    assert response.success, f"An√°lisis debe ser exitoso: {response.error_message}"
    assert "suggestions" in response.data
    assert "validation_passed" in response.data
    assert "model_used" in response.data
    
    print("‚úÖ Test Claude Terminology Analysis (mejorado): PASSED")


def test_claude_utilities():
    """‚úÖ MEJORADO: Test de utilidades espec√≠ficas de Claude."""
    # Test validaci√≥n API key
    assert validate_claude_api_key("sk-ant-1234567890abcdef1234567890") == True
    assert validate_claude_api_key("invalid-key") == False
    assert validate_claude_api_key("sk-wrong-prefix") == False
    assert validate_claude_api_key("sk-ant-short") == False
    assert validate_claude_api_key("") == False
    assert validate_claude_api_key(None) == False
    
    # Test modelos soportados
    models = get_supported_models()
    assert "recommended" in models
    assert "terminology" in models["recommended"]
    assert "pricing" in models
    assert "context_windows" in models
    
    # Test estimaci√≥n de tiempo
    estimation = estimate_claude_processing_time(2000, "medium", "terminology")
    assert estimation["estimated_seconds"] > 0
    assert estimation["min_seconds"] <= estimation["estimated_seconds"]
    assert "task_factor" in estimation
    assert "time_category" in estimation
    assert "user_message" in estimation
    
    # Test contextos acad√©micos
    contexts = get_academic_discipline_contexts()
    assert len(contexts) > 0
    assert "philosophy" in contexts or "filosofia" in contexts
    
    print("‚úÖ Test Claude Utilities (mejorado): PASSED")


def test_json_parsing_robust():
    """‚úÖ MEJORADO: Test de parsing robusto de respuestas JSON."""
    import logging
    logger = logging.getLogger("test")
    claude = ClaudeAPIIntegration("sk-ant-test12345678901234567890", logger)
    
    # Test extracci√≥n de JSON normal
    sample_text = 'Here is the analysis: {"terminos_sugeridos": [{"termino_original": "test"}]}'
    json_content = claude._extract_json_from_text_robust(sample_text)
    assert json_content is not None
    assert "terminos_sugeridos" in json_content
    
    # Test JSON malformado
    malformed_text = "Analysis: {terminos_sugeridos: [{termino_original: 'test',}]}"
    cleaned_json = claude._clean_malformed_json(malformed_text)
    assert cleaned_json is not None
    
    # Test validaci√≥n estructural
    valid_term_data = {
        "terminos_sugeridos": [
            {"termino_original": "test", "traduccion_sugerida": "prueba"}
        ]
    }
    assert claude._validate_terminology_structure(valid_term_data) == True
    
    invalid_term_data = {"wrong_key": []}
    assert claude._validate_terminology_structure(invalid_term_data) == False
    
    # Test parsing manual mejorado
    fallback_text = """
    Term: Dasein ‚Üí ser-ah√≠
    "Begriff": "concepto"
    - Vorstellung: representaci√≥n
    """
    suggestions = claude._manual_parse_terminology_enhanced(fallback_text, AcademicDiscipline.PHILOSOPHY)
    assert len(suggestions) >= 2
    assert any(s.source_term == "Dasein" for s in suggestions)
    assert all(s.confidence > 0 for s in suggestions)  # Verificar heur√≠sticas de confidence
    
    print("‚úÖ Test JSON Parsing Robust (mejorado): PASSED")


def test_model_fallback():
    """‚úÖ NUEVO: Test de funcionalidad de modelo fallback."""
    import logging
    logger = logging.getLogger("test")
    
    # Test configuraci√≥n de modelos
    claude = ClaudeAPIIntegration(
        "sk-ant-test12345678901234567890", 
        logger,
        model="claude-3-opus-20240229",
        fallback_model="claude-3-haiku-20240307"
    )
    
    assert claude.primary_model == "claude-3-opus-20240229"
    assert claude.fallback_model == "claude-3-haiku-20240307"
    assert claude.current_model == "claude-3-opus-20240229"
    
    print("‚úÖ Test Model Fallback: PASSED")


def test_confidence_estimation():
    """‚úÖ NUEVO: Test de estimaci√≥n de confidence por heur√≠sticas."""
    import logging
    logger = logging.getLogger("test")
    claude = ClaudeAPIIntegration("sk-ant-test12345678901234567890", logger)
    
    # Test confidence con t√©rmino t√©cnico largo
    confidence_high = claude._estimate_term_confidence("Phenomenology", "fenomenolog√≠a", 'Technical term: "Phenomenology"')
    assert confidence_high > 0.6
    
    # Test confidence con t√©rmino corto com√∫n
    confidence_low = claude._estimate_term_confidence("the", "el", "the ‚Üí el")
    assert confidence_low < 0.5
    
    # Test priority estimation
    priority_high = claude._estimate_term_priority("Phenomenological", AcademicDiscipline.PHILOSOPHY)
    assert priority_high == "alta"
    
    priority_low = claude._estimate_term_priority("and", AcademicDiscipline.PHILOSOPHY)
    assert priority_low == "baja"
    
    print("‚úÖ Test Confidence Estimation: PASSED")


async def run_all_tests():
    """Ejecuta todos los tests embebidos."""
    print("üß™ Ejecutando tests de claude_integration.py (POST-AUDITOR√çA)...")
    
    try:
        test_claude_utilities()
        test_json_parsing_robust()
        test_model_fallback()
        test_confidence_estimation()
        await test_claude_terminology_analysis()  # Omitido si no hay API key
        
        print("\n‚úÖ Todos los tests de claude_integration.py (POST-AUDITOR√çA) pasaron!")
        print("\nüèÜ MEJORAS IMPLEMENTADAS:")
        print("  ‚úÖ M√©todo centralizado para llamadas a Claude (_call_claude)")
        print("  ‚úÖ Modelo configurable con fallback autom√°tico")
        print("  ‚úÖ Validaci√≥n estructural estricta de respuestas JSON")
        print("  ‚úÖ Parsing robusto con m√∫ltiples estrategias de limpieza")
        print("  ‚úÖ Fallback manual mejorado con heur√≠sticas de confidence")
        print("  ‚úÖ Extracci√≥n robusta de contenido de respuestas")
        print("  ‚úÖ Validaci√≥n exhaustiva de entrada y limpieza de datos")
        print("  ‚úÖ Estimaci√≥n de tiempo espec√≠fica por tipo de tarea")
        
    except Exception as e:
        print(f"\n‚ùå Test fall√≥: {e}")
        raise


if __name__ == "__main__":
    """Ejecutar tests al correr el m√≥dulo directamente."""
    import logging
    import asyncio
    logging.basicConfig(level=logging.INFO)
    
    asyncio.run(run_all_tests())